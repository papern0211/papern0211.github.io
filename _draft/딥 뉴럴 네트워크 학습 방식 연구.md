# 딥 뉴럴 네트워크 학습 방식 연구
## __SELFIE: Refurbishing Unclean Samples for Robust Deep Learning__
데이터에서 잘못된 라벨링 된 데이터가 존재 가능하다(ex. Cheetah vs. Jaguar 의 무늬).
라벨링 오류는 다음과 같은 요인으로 발생 가능하다.
  - 소프트웨어 오류
  - 수작업 과정에서 발생하는 오류

Noisy 라벨링이 있는 경우, Test data에 대해 generalization 성능이 매우 떨어진다.
</br></br>

이를 해결하기 위한 큰 두개의 흐름이 존재하는데,
  - Loss correction: Confidence에 맞춰 가중치를 조정  
  ex) ActiveBias (NIPS'17) 
      - 주어진 mini-batch에 대해 Forward step을 진행하고, 각 샘플에 대해 __importance__ ui (ex. variance of predictions) 활용
      - 만약, variance가 크다면 Loss에 normalized ui 을 곱하여 re-weight.
      - __단점__: noise가 누적이 될 가능성이 존재
  - Sample selection: 추정을 잘못 하는 것은 과감히 제외  
  ex) Loss-based Sepration in Coteaching (NIPS'18)
    - 지금 단계에서 예측 결과가 정확해 보이는 Loss에 대해서, 중점적으로 loss을 계산
    - __단점__: 즉, Batch에서 일부의 sample만 반영되는 상황 발생 → 쉬운 케이스에 대해서만 학습만 될 가능성이 존재
</br></br>

### __Key idea: Refurbishng__
Refurbishable samples R 을 도입하여, corrected loss을 추가한다.
그러면 R 과 C (clean set)을 어떻게 찾을까???
 - Clean Sample, C  
low-loss sample은 Clean sample
 - Refurbishable Sample, R  
여러 iteration에서 consistent한 label을 한 케이스가 존재한다면, label 자체를 변경

이렇게 진행하면 false correction이 줄어들 것으로 가정하고, 이 과정을 반복하면 할 수록 모델의 성능은 향상이 되고,
또한 Refurbishable Sample이 늘어난다.

노이즈 타입 변경 방법은 두가지 방법이 manupulate 가능한데,
  - pair noises
  - synthetic noises

이러한 방법으로 인위적으로 바꾸는 것에 대해서, 실제와 괴리가 존재 가능함
결국, cloud sourcing을 통해 실제 사람들에게 데이터를 획득하고, Nosiy 라벨 데이터를 획득해서 실험하여 결과 확인

</br></br>
## __Carpe diem: Seize the Samples "at the Moment" for Adaptive Batch Selection__
Batch selection을 어떻게 할지 고민한 논문이다. 일반적으로 Random하게 선택하는데, 어떻게 하면 효과적으로 batch을 선택할까?
직관적으로 다음의 방법으로 고민해보면,
  - Difficulty-based selection: Easy sample, Hard sample 기준
  - Uncertainty-based selection: historical prediction을 이용해 uncertainty가 높은 sample 위주로 선택  

본 논문은, historical prediction을 이용하는데 있어, __과거 어디까지 봐야하는지 여부__ 를 연구하고 하나의 방법을 제안하였다.
아이디어는 매우 단산하다. Sliding window을 도입해, 최신 iteration에 대한 uncertainty만 본다.

방법은 다음과 같다  
  1. Uncertainty은 sliding window내의 예측 결과에 대해 Empirical Entropy을 계산
  1. 계산된 Uncertainty을 Quantization을 하고, 이를 샘플링 확률에 반영 (exponentially decaying with the quntizaed index)
  1. Selection pressure을 도입하여, 일부 데이터에 overfitting 되는 부분을 방지 

결국 두가지 부분에서 장점을 주장한다.
  - Fast training
  - Improve generalization

</br></br>
## __Ada-Boundary: Acceleration DNN Training via Adaptive Boundary Batch Selection__
Hard sample만 batch로 선택시, overfitting 문제가 발생한다. 학습 능력을 높이려면, 중간정도의 어려움이 있는 sample을 추가하자는 것이 핵심 아이디어이다.  
이를 위해 decision boundary에 가까운 sample들 위주로 선택하는 방안을 제시한다. 2번째 논문과 마찬가지로, distnace의 결과를 quantization하고, 이를 sampling 확률에 반영하였다.













