---
title:  "[논문 리뷰] TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"
excerpt: "TVM: An Automated End-to-End Optimizing Compiler for Deep Learning"

categories:
  - Deep Learning
tags:
  - Deep learning compiler
classes: wide
last_modified_at: 2021-01-03T11:00:00+09:00
---
__[arxiv link](https://arxiv.org/pdf/1802.04799.pdf)__  

다양한 하드웨어 장치에 딥러닝 모델을 탑재하는데 있어 많은 제약이 따른다. 사용할 수 있는 리소스도 하드웨어마다 천차만별이고, 하드웨어에 최적화된 API 함수들을 적용하기 위해서는 수동으로 최적화하는 노력이 들어갈 수 밖에 없다.

하드웨어단의 연산 최적화를 자동적으로 하게끔 많은 연구들이 진행되었는데, 크게 2가지 어려움이 존재하였다.
- _Lveraging Specific Hardware Features and Abstractions_
  - CPU, GPU 마다 프로세싱 유닛들이 독자적으로 발전하였는데, 각각의 연산을 활용한 최적화된 코드를 자동적으로 생성하는 것은 쉬운 일이 아님
  - 입력 변수도 다양하고, 효율적인 메모리 사용을 위한 각각의 특별한 조건이 필요하는 등 효율적으로 이러한 부분 조절이 필요
- _Large Search Space for Optimization_
  - 메모리 접근, 쓰레딩 패턴, 하드웨어 primitives 간의 수백만가지 조합을 모두 찾고 확인해야 된다면, 막대한 시간 소요
  - Pre-defined cost 모델을 이용해 이러한 문제를 해결할 수도 있지만, 이 경우 하드웨어마다 이러한 cost 모델을 만들어야 하며, 최근에 만들어진 하드웨어에서는 complexity가 높아져 이마져도 쉬운 작업이 아님

이러한 어려움을 극복하기 위해, __TVM__ 은 3가지 key 모듈을 제안한다.
- _Tensor expression language_
  - 다양한 하드웨어 별로 다른 버젼의 코드를 생성
- _Automated program optimzation framework_
  - ML-based cost 모델을 이용해 최적화
- _Graph rewriter_
  - High/low operator-level 최적화를 이용

TVM의 동작원리는 다음과 같다

![TVM 동작원리, figure2](/assets/images/2021-01-03-TVM/figure2.jpg)

1. 입력된 모델을 computational graph로 표현
1. High-level dataflow rewriting을 통해 최적화된 computational graph 도출
1. Tensor expression language을 활용해 각각의 operator가 저장되고, 타겟 하드웨어로부터 주어진 operator에서 최적 코드 조합을 만듬
1. ML-based cost 모델을 통해 최적 operation을 찾음
1. Deploy 할 수 있는 형태의 모듈로 패키징

자, 이제부터 각각의 핵심요소에 대해 알아보자.

## __Opimizing Computational Graph__
TVM은 computational graph 표현을 이용하여, high-level 최적화를 적용한다. Graph-level 최적화에는 _operator fusing_, _constant folding_, _static memory planning pass_, _data layout transformation_ 등의 방법이 적용된다. 다음의 두 가지 방법에 대해 논무에서는 설명을 하였다.

### 1. Operator Fusion
Operator Fusion은 여러개의 operators을 중간 단계 결과 저장없이, 하나의 커널로 합치는 작업을 말한다. 이 방법은 특히 GPU 사용시 획기적으로 연산을 줄일 수 있다. TVM에서는 operator을 크게 네가지 카테고리로 구분하고 (injective, reduction, complex-out-fusion, opaque), 카데고리별 fusion rule을 만들어 적용하였다. 다양한 딥러닝 layer에 대해 적용을 해서 성능향상을 보여주었으며, 일반적으로 1.2~2.0배 수준의 속도 향상을 이뤄냈다.

### 2. Data layout transformation
일반적으로 데이터를 저장하는데 사용하는 layout은 row-major 혹은 column-majog이다. TVM에서는 특별한 형태의 layout을 사용하는데, 예를 들어 $4 \times 4$ 매트릭스 연산을 이용하는 경우 데이터를 $4 \times 4$ 형태로 tiling을 하여 구성 할 수 있고, 이를 통해 _memory access locality_ 최적화가 가능하다. 각각의 operation 별로 주어진 메모리 조건하에 이러한 data layout을 구성한다.

## __General Tensor operation__
Operator library가 주어진 경우, high-level graph 최적화는 매우 효과적임을 많은 연구를 통해 확인이 되었지만, 이러한 방법은 타겟 하드웨어 갯수가 점차 늘어나는 현 상황에서 지속적으로 활용되기는 쉽지 않다. Data layout, data type, accelator intrinsic 등 다양한 조합을 가지고 최적화 커널을 매번 직접 구현하는 것은 쉽지 않기에 TVM에서는 주어진 operator에서 다양한 implementation을 가능케 하는 코드 생성법을 제안한다.

### 1. Tensor Expression and Schedule Space
Graph-level 표현과 달리, Tensor operations의 구현은 약각 불명확하며, 또한 각각의 operation들은 index 연산으로 표현된다. 다음의 코드는 transposed matrix 곱셈 하는 예제를 보여주는데,

![연산 예제, figure transposed multiplication](/assets/images/2021-01-03-TVM/figure_transposed.jpg)

Tensor expression language 에서는 tensor의 모양을 어떻게 하고/어떻게 element을 계산하리 정도만 표현하고, 따로 loop 구조를 어떻게 할지와 같은 자세한 사항은 표현되지 않는다. 이는 다양한 하드웨어별로 최적화시 flexibility을 제공할 수 있는 방법으로, [Halide](https://people.csail.mit.edu/jrk/halide-pldi13.pdf)의 아이디어 (__연산과 최적화 스케쥴링은 분리해야 한다__)를 기반으로 한다.

low-level 코드로 변환을 위한 최적화 스케쥴링은 단계별로 하나씩 추가해가면서 진행한다. 이는 최적화 스케쥴링이 진행되는 과정에서, 프로그램의 논리적 equivalence을 유지하기 위함이다. 아래 그림에 이러한 스케쥴링 과정이 잘 나타나 있다.
![최적화 스케쥴링 예제, figure5](/assets/images/2021-01-03-TVM/figure5.jpg)

결국, TVM에서 다양한 하드웨어에 다양한 최적화 셋을 제공하기 위해서는 충분한 스케쥴 primitives을 제공 해야 할 것이다.
> __Comments__: 이부분이 어려운점이 아닌가? 결국은 이러한 스케쥴링을 지속적으로 업데이트 해야 되는 것 같은데...

### 2. Nested Parallelism with Cooperation
일반적으로 nested parallelism을 적용해서 병렬화를 구현한다. 즉, 타겟 아키텍쳐별 메모리 hierarchy을 효과적으로 이용하기 위해서는 각각의 task별 subtask을 반복적으로 수행하도록 하는데, 이러한 방법을 _shared-nothing nest parallelism_ 이라 부른다. 

이와 다르게 share 메모리를 활용해서 여러 쓰레드들이 데이터를 공통으로 fetch하여 사용하도록 하는데, 이는 전체적으로 데이터 재사용을 가능케 하여 속도 향상을 이뤄낸다.

TVM에서는 _momory scope_ 라는 개념을 소개하는데, 이를 통해 각각의 연산에 어떤 메모리를 할당 할지를 정할 수 있다. 또한 _memory synchronization barrier_ 을 적절하게 추가하도록 하여, 개발자가 중간에 디버깅을 할 수 있도록 도와준다.

### 3. Tensorlization
딥러닝의 작업은 matrix 곱이나 1-D convolution과 같은 연산으로 분해가 가능하다. 이러한 분해를 통해 효과적으로 성능을 높일 수 있는데, 앞서 설명한 바와 같이 스케쥴링 기반 컴파일에 적용하기 위해서는 seamless하게 이를 적용하도록 프레임워크가 지원해야 한다 (즉, TVM은 할 수 있다!). 앞으로 추가될 수 있는 새로운 accelerator을 위해서도 고정된 형태의 primitive을 지원하기 보단 확정가능한 방법을 사용해야 한다.

이를 위해 TVM에서는 Tensor-intrinsic 선언 부분과 target device instrinsic 부분을 분리하였다. 게다가 tensorize schedule primitive을 도입함으로써 계산 유닛을 해당하는 intrinsic으로 변환 가능하였다.

Tensorlization은 하드웨어에 특화된 intrinsic을 스케쥴과 분리시킴으로써, TVM을 다양한 하드웨어에 쉽게 확장 가능하도록 하였다.
> __Comments__: 범용적인 요소가 아닌 경우에서는 장점이 존재하는 걸까? 결국 하드웨어에 맞게 lowering rule을 선언하는 부분도 하드웨어별로 작업을 해야 되는 것이 아닌가?

### 4. Explicit Memory Latency Hiding
_Latency hiding_ 은 다음과 같이 설명될 수 있다.
> Latency hiding improves machine utilization by enabling the execution of usefuloperations by a device while it is waiting for a communication operation ormemory access to complete. Prefetching, context switching, and instruction-levelparallelism are mechanisms for latency hiding.

TVM에서는 하나의 intrinsic stream 형태로 프로그램을 변환함으로써, 자동적으로 low-level explicit synchronization을 구현한다. 순서는 다음과 같다.
1. 정ㅇ확한 연산이 보장될 수 있는 부분을 기준으로 synchronize barrier 설정
1. Operation을 thread별로 interleaving
1. 다시 병렬 파이프라인으로 변환

## __Automating Optimizatin__
TVM에서는 각 layer별로 optimal oeprator을 찾기 위해서 2가지 요소를 제안하였다.
- Automated schedule optimizer: 새로운 configuration 후보군 제안
- Cost model: 주어진 configuration에서 성능을 예측 (prediction)
![Overview, figure11](/assets/images/2021-01-03-TVM/figure11.jpg)

### 1. Schedule Space Specification
Tensor expression language에 기술된 연산 정보를 기반으로 자동적으로 configuration 후보군을 찾을 수 있다. 또한 사용자의 도메인 지식이 반영될 수 있도록, template specification API을 제공한다.

### 2. ML-based Cost Model
최적회돈 configuration을 찾기 위해서는 성능을 적확히 체크할 수 있는 cost model이 필요하다. Pre-defined cost model을 사용하면 사용자의 의도와 디바이스에 맞게 최적화된 configuration을 찾을 수 있겠지만, cost model을 구성하는데 상당한 노력이 수반된다.

TVM에서는 통계적 방법을 이용해 cost 모델링 문제를 해결했다. 각각의 스케쥴마다 변형된 lower loop program을 입력으로 넣어 준 뒤, running 시간을 예측한다. 모델의 경우 exploration 단계에서 모아진 runtime 측정용 데이터를 이용해서 학습하는데, 이를 위해 특별히 사용자에게 데이터를 요구하지 않는다.

그렇다면 cost model에 사용하기 위해서 무엇을 고려해야 될까? 바로 quality 와 speed이다. Cost model을 재학습하고 다시 파라미터 업데이트를 하는 것 또한 오버헤드이고, 이러한 오버헤드는 실제 하드웨어에서 성능을 측정하는데 걸리는 시간보다 작아야 한다. 

TVM 논문에서는 gradient tree boosting model (XGBoost 기반)을 사용하였는데, model에 입력으로는 memory access 횟수, 각 loop level마다 메모리 버퍼 재사용 비율 등을 사용하였다. NN (TreeRNN)을 활용해서도 비슷하게 적용해 봤는데, 속도면에서는 gradient tree boosting model이 낫기에 저자들은 이를 선택했다. 

### 3. Schedule Exploration
일단 cost model이 선택되고 나면, 이를 통해 최적의 configuration을 찾을 수 있다. 각 iteration 마다, explorer은 ML model의 예측을 이용해 업데이트에 사용할 데이터를 모은다. 일반적으로 가장 쉽게 활용할 수 있는 방법은 top-k prediction을 선택하는 것인데, large space에서 적용할 경우 intractable 해서 권하지 않는다. 그 대신에 저자들은 simulated annealing 알고리즘을 이용하여, 매 순간마다 가까운 configuration으로 random하게 이동하면서 찾고, 만약 cost가 감소되면 성공적으로 transition이 되었다고 판단했다. Cost model은 이 과정을 수렴할때까지 반복적으로 진행한다.

### 4. Distributed Device Pool and RPC
TVM의 Remote Protocol Call (RPC)는 dynamic upload, cross-compiled modules 그리고 runtime convention에 사용되는 함수를 지원한다. 이러한 인터페이스를 통해 프로그램을 host에서 compile하고, remote device로 요청하여 함수를 동작하게 한뒤 결과를 확인 할 수 있다. 이러한 방법을 통해 여러 디바이스에 걸쳐 자동적으로 위 작업을 진행 할 수 있다.
> __Comments__: 실제 여러 모델에 걸쳐 최적화가 필요한 경우 좋은 방법인 것 같다. 쉽게 말해 매번 cross-compile을 위해 뭔가 세팅하고 고쳐야 되는 부분이 최소화 된다는 것이다.

## Evaluation
저자들은 다양한 환경에서 TVM의 효용성을 판단하였다. Server-class GPU, Embedded CPU Evaluation, Embedded GPU Evalution 및 FPGA Accelerator Evalution 에서 TVM 성능을 평가하였다. 각 환경에서 TVM은 기존의 최적화 혹은 직접 최적화 한 경우 보다도 좋은 성능을 보여주었다. (자세한 성능은 논문 참고)